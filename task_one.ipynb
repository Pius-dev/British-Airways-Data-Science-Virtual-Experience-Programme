{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n",
      "Scraping page 21\n",
      "   ---> 2100 total reviews\n",
      "Scraping page 22\n",
      "   ---> 2200 total reviews\n",
      "Scraping page 23\n",
      "   ---> 2300 total reviews\n",
      "Scraping page 24\n",
      "   ---> 2400 total reviews\n",
      "Scraping page 25\n",
      "   ---> 2500 total reviews\n",
      "Scraping page 26\n",
      "   ---> 2600 total reviews\n",
      "Scraping page 27\n",
      "   ---> 2700 total reviews\n",
      "Scraping page 28\n",
      "   ---> 2800 total reviews\n",
      "Scraping page 29\n",
      "   ---> 2900 total reviews\n",
      "Scraping page 30\n",
      "   ---> 3000 total reviews\n",
      "Scraping page 31\n",
      "   ---> 3100 total reviews\n",
      "Scraping page 32\n",
      "   ---> 3200 total reviews\n",
      "Scraping page 33\n",
      "   ---> 3300 total reviews\n",
      "Scraping page 34\n",
      "   ---> 3400 total reviews\n",
      "Scraping page 35\n",
      "   ---> 3500 total reviews\n",
      "Scraping page 36\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 37\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 38\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 39\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 40\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 41\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 42\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 43\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 44\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 45\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 46\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 47\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 48\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 49\n",
      "   ---> 3537 total reviews\n",
      "Scraping page 50\n",
      "   ---> 3537 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 50\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified | Regarding the aircraft and seat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified | I travelled with British Airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Food was lousy. Who ever is pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | Had the worst experience. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The ground staff were not h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  Not Verified | Regarding the aircraft and seat...\n",
       "1  Not Verified | I travelled with British Airway...\n",
       "2  Not Verified |  Food was lousy. Who ever is pl...\n",
       "3  ✅ Trip Verified | Had the worst experience. Th...\n",
       "4  ✅ Trip Verified |  The ground staff were not h..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset now\n",
    "df = pd.read_csv('data/BA_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Verified | Regarding the aircraft and seat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not Verified | I travelled with British Airway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Not Verified |  Food was lousy. Who ever is pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>✅ Trip Verified | Had the worst experience. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>✅ Trip Verified |  The ground staff were not h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews\n",
       "0           0  Not Verified | Regarding the aircraft and seat...\n",
       "1           1  Not Verified | I travelled with British Airway...\n",
       "2           2  Not Verified |  Food was lousy. Who ever is pl...\n",
       "3           3  ✅ Trip Verified | Had the worst experience. Th...\n",
       "4           4  ✅ Trip Verified |  The ground staff were not h..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pius/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # Remove non-text characters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # Convert all text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "\n",
    "    return text\n",
    "\n",
    "clean_reviews = [clean_text(review) for review in reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cleaned reviews to a new column in the dataframe\n",
    "df['cleaned_reviews'] = clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to the same CSV file, overwriting the old data\n",
    "df.to_csv(\"data/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Verified | Regarding the aircraft and seat...</td>\n",
       "      <td>verified regarding aircraft seat business clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not Verified | I travelled with British Airway...</td>\n",
       "      <td>verified travelled british airways sweden los ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Not Verified |  Food was lousy. Who ever is pl...</td>\n",
       "      <td>verified food lousy ever planning asian hindu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>✅ Trip Verified | Had the worst experience. Th...</td>\n",
       "      <td>trip verified worst experience flight london t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>✅ Trip Verified |  The ground staff were not h...</td>\n",
       "      <td>trip verified ground staff helpful felt like w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews   \n",
       "0           0  Not Verified | Regarding the aircraft and seat...  \\\n",
       "1           1  Not Verified | I travelled with British Airway...   \n",
       "2           2  Not Verified |  Food was lousy. Who ever is pl...   \n",
       "3           3  ✅ Trip Verified | Had the worst experience. Th...   \n",
       "4           4  ✅ Trip Verified |  The ground staff were not h...   \n",
       "\n",
       "                                     cleaned_reviews  \n",
       "0  verified regarding aircraft seat business clas...  \n",
       "1  verified travelled british airways sweden los ...  \n",
       "2  verified food lousy ever planning asian hindu ...  \n",
       "3  trip verified worst experience flight london t...  \n",
       "4  trip verified ground staff helpful felt like w...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we apply sentiment analysis using TextBlob to calculate the polarity of each review.\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "sentiment_scores = []\n",
    "\n",
    "for review in clean_reviews:\n",
    "    blob = TextBlob(review)\n",
    "    sentiment_scores.append(blob.sentiment.polarity)\n",
    "    \n",
    "df['sentiment_score'] = sentiment_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Not Verified | Regarding the aircraft and seat...</td>\n",
       "      <td>verified regarding aircraft seat business clas...</td>\n",
       "      <td>-0.016892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Not Verified | I travelled with British Airway...</td>\n",
       "      <td>verified travelled british airways sweden los ...</td>\n",
       "      <td>-0.064912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Not Verified |  Food was lousy. Who ever is pl...</td>\n",
       "      <td>verified food lousy ever planning asian hindu ...</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>✅ Trip Verified | Had the worst experience. Th...</td>\n",
       "      <td>trip verified worst experience flight london t...</td>\n",
       "      <td>-0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>✅ Trip Verified |  The ground staff were not h...</td>\n",
       "      <td>trip verified ground staff helpful felt like w...</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews   \n",
       "0           0  Not Verified | Regarding the aircraft and seat...  \\\n",
       "1           1  Not Verified | I travelled with British Airway...   \n",
       "2           2  Not Verified |  Food was lousy. Who ever is pl...   \n",
       "3           3  ✅ Trip Verified | Had the worst experience. Th...   \n",
       "4           4  ✅ Trip Verified |  The ground staff were not h...   \n",
       "\n",
       "                                     cleaned_reviews  sentiment_score  \n",
       "0  verified regarding aircraft seat business clas...        -0.016892  \n",
       "1  verified travelled british airways sweden los ...        -0.064912  \n",
       "2  verified food lousy ever planning asian hindu ...         0.006250  \n",
       "3  trip verified worst experience flight london t...        -0.160000  \n",
       "4  trip verified ground staff helpful felt like w...         0.133333  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAf0klEQVR4nO3de7xVdZ3/8ddbUBTFgAEJAUWLbNBfopJdLQtnvJY2vy7MLwsdy7H8WXaZRLtZv5hoZuqn/fw5ZWqiZop3UiuRQmtSCfCKlyRBOIGAt7ykGPiZP77fs9wc9uEszjlrn33OeT8fj/3Ya33Xd33XZ6+zz/6s63cpIjAzMwPYpqcDMDOz5uGkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBS6Mck/UDSV7uprd0kPS9pQB6fL+kT3dF2bu/nkqZ1V3tbsdxvSXpC0uONXnadWJ6XtGdPx2F9m5NCHyVpuaQXJT0n6RlJv5N0kqTibx4RJ0XE/ynZ1iFbqhMRKyJip4jY2A2xnynp0jbtHx4Rs7ra9lbGMQ74AjAxIl7bTp0zJC3LP9gtkq7opmVvllTz+n20O9rfylg6/PtXtR6s8ZwU+rb3RcQQYHdgJnAacEF3L0TSwO5us0nsDjwZEWvrTcx7Lh8DDomInYDJwLwGxtcUGrEe+vB3rPlEhF998AUsJ/2T1pYdCLwC7JPHLwK+lYdHADcAzwBPAb8hbTRckud5EXge+BIwHgjgBGAFcFtN2cDc3nzg28AC4M/A9cDwPO1goKVevMBhwMvAX/Py7qlp7xN5eBvgK8BjwFrgYuA1eVprHNNybE8AX97CenpNnn9dbu8ruf1D8md+JcdxUZ15zwHO6qDtC4DVwJ+AbwED8rTjgN8C/wE8DSwDDs/TZgAbgZfyss/J5QG8vuZvdy7w81znv4DXAmfl9h4C9quJZVfg6vw5lwGfqZl2JjA7r4fngCXA5Dxts79/J9bDcODHwKoc23U10z4JLCV95+YAu9ZMC+Bk4BFgWS47Crib9D39HfCmmvqn5fX8HPAwMKWn/w9746vHA/Croj9snaSQy1cAn8rDF/FqUvg28ANg2/w6CFC9tnj1h/diYEdgB+onhT8B++Q6VwOX5mkH005SyMNnttatmT6fV5PCP+Ufkj2BnYBrgEvaxPajHNe+wHrgb9tZTxeTEtaQPO8fgBPai7PNvMfmH7N/IW0dD2gz/Trgh/nz70JKkP+cpx1HSnyfBAYAnyL9aKrt561pr21SeAI4ANge+BXpx/7jub1vAb/OdbcBFgFfA7bL6+1R4NCa9f0ScESe99vAHR19l7ZiPdwIXAEMI3233p3L35s/w/7AIOD/Abe1+bxzSUllh1xvLfCWHOe0HNsgYC9gJTmp5L/l63r6/7A3vnz4qP9ZRfona+uvwGhg94j4a0T8JvJ/1xacGREvRMSL7Uy/JCLuj4gXgK8CH249Ed1FHwW+FxGPRsTzwOnA1DaHGL4RES9GxD3APaTksIkcy0eA0yPiuYhYDnyXdCikQxFxKXAKcChwK7BW0vTc9ijgcODUvI7WAv8XmFrTxGMR8aNI52Fmkdb/qNJrAa6NiEUR8RJwLfBSRFyc27sC2C/XezMwMiK+GREvRzov8aM2sfw2Im7K815CnfXVyfUwOq+HkyLi6fzdujXP+lHgwohYHBHrSX/Ht0kaX9P8tyPiqfwd+yTww4i4MyI2RjrHtB54K2nPahAwUdK2EbE8Iv5Y9jPYq3ycrv8ZQ9qqa+vfSVuMN0sCOC8iZnbQ1sqtmP4YaStxRLkwt2jX3F5t2wPZ9Ae19mqhv5D2KNoaQdpybtvWmLKBRMRPgJ9I2hY4Jg/fRTpMsi2wOq9PSFvstevk8Zp2/pLr1YuzPWtqhl+sM97a1u7ArpKeqZk+gHSIcLNYSOtre0kDI2JDmUA6WA9PRcTTdWbbFVhc08bzkp4krf/lubh2fe0OTJN0Sk3ZdqS9g1slnUr6Du8t6ZfA5yNiVZn47VXeU+hHJL2Z9A/327bT8pbyFyJiT+B9wOclTWmd3E6THe1JjKsZ3o20N/IE8AIwuCauAcDIrWh3FekHorbtDWz6o1jGEzmmtm39aSvbIW8BXwncSzpktpK0FTsiIobm184RsXfZJrc2hi1YSTomP7TmNSQijujuWNpZD8MlDa1TfZO/o6Qdgb9h0/Vfu+yVwIw2n2NwRPw0L/uyiHhnbjOA75SN217lpNAPSNpZ0lHA5aRj9ffVqXOUpNcrba4+S9odb728dA3pOPTWOlbSREmDgW8CV+XDE38gbYkembcsv0La9W+1Bhhfe/lsGz8FPidpD0k7Af8KXFF2q7ZVjmU2MEPSEEm7A58HLt3ynImk4/JnGCJpG0mHA3sDd0bEauBm4Lt5/W8j6XWS3l0yvM6u83oWAM9KOk3SDpIGSNonbyR0OZYS6+HnwLmShknaVtK78qyXAcdLmiRpEOnveGc+jFfPj4CTJL1FyY41y91L0ntzOy+R9pS6fHl0f+Sk0Lf9TNJzpC2sLwPfA45vp+4E4BbSFSa3A+dGxPw87dvAV/L9Dl/ciuVfQjoh+jjpZOhnACLiz8CngfNJW4UvAC01812Z35+UtJjNXZjbvo10cvUl0jHtzjglL/9R0h7UZbn9Mp4FziCdvH8G+DfSSfzWPbGPkw5vPEA6jHIV6bxBGWcDH5T0tKTvl5ynrpz83gdMIq2vJ0jr/jUlm+jo79/RevgYaY/sIdKJ4lNzXPNI55quJl2h9To2Pc/R9nMsJJ1XOIe0PpeSTthD2qiYmT/b46QT+2eU/HxWo/VKBzMzM+8pmJnZq5wUzMys4KRgZmYFJwUzMyv06pvXRowYEePHj+/pMMzMepVFixY9EREj603r1Ulh/PjxLFy4sKfDMDPrVSQ91t40Hz4yM7OCk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzQq++o9msrxo//cZOz7t85pHdGIn1N95TMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzKzgpmJlZwUnBzMwKvk/BrCJdudfArKdUuqcgaaikqyQ9JOlBSW+TNFzSXEmP5PdhNfVPl7RU0sOSDq0yNjMz21zVh4/OBn4REW8E9gUeBKYD8yJiAjAvjyNpIjAV2Bs4DDhX0oCK4zMzsxqVJQVJOwPvAi4AiIiXI+IZ4GhgVq42CzgmDx8NXB4R6yNiGbAUOLCq+MzMbHNV7insCawDfizpLknnS9oRGBURqwHy+y65/hhgZc38LblsE5JOlLRQ0sJ169ZVGL6ZWf9TZVIYCOwP/GdE7Ae8QD5U1A7VKYvNCiLOi4jJETF55MiR3ROpmZkB1SaFFqAlIu7M41eRksQaSaMB8vvamvrjauYfC6yqMD4zM2ujsqQQEY8DKyXtlYumAA8Ac4BpuWwacH0engNMlTRI0h7ABGBBVfGZmdnmqr5P4RTgJ5K2Ax4FjiclotmSTgBWAB8CiIglkmaTEscG4OSI2FhxfGZmVqPSpBARdwOT60ya0k79GcCMKmMyM7P2uZsLMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzKzgpmJlZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCpU+o9mstxs//caeDsGsobynYGZmBScFMzMrOCmYmVmh0qQgabmk+yTdLWlhLhsuaa6kR/L7sJr6p0taKulhSYdWGZuZmW2uEXsK74mISRExOY9PB+ZFxARgXh5H0kRgKrA3cBhwrqQBDYjPzMyynjh8dDQwKw/PAo6pKb88ItZHxDJgKXBg48MzM+u/qk4KAdwsaZGkE3PZqIhYDZDfd8nlY4CVNfO25DIzM2uQqu9TeEdErJK0CzBX0kNbqKs6ZbFZpZRcTgTYbbfduidKMzMDKt5TiIhV+X0tcC3pcNAaSaMB8vvaXL0FGFcz+1hgVZ02z4uIyRExeeTIkVWGb2bW71SWFCTtKGlI6zDw98D9wBxgWq42Dbg+D88BpkoaJGkPYAKwoKr4zMxsc1UePhoFXCupdTmXRcQvJP0emC3pBGAF8CGAiFgiaTbwALABODkiNlYYn5mZtVFZUoiIR4F965Q/CUxpZ54ZwIyqYjIzsy3zHc1mZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFIwM7OCk4KZmRWcFMzMrFD1Q3bMrMHGT7+x0/Mun3lkN0ZivZH3FMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgUnBTMzK1SeFCQNkHSXpBvy+HBJcyU9kt+H1dQ9XdJSSQ9LOrTq2MzMbFOlkoKkfbqwjM8CD9aMTwfmRcQEYF4eR9JEYCqwN3AYcK6kAV1YrpmZbaWyewo/kLRA0qclDS3buKSxwJHA+TXFRwOz8vAs4Jia8ssjYn1ELAOWAgeWXZaZmXVdqaQQEe8EPgqMAxZKukzS35WY9SzgS8ArNWWjImJ1bnc1sEsuHwOsrKnXkss2IelESQslLVy3bl2Z8M3MrKTS5xQi4hHgK8BpwLuB70t6SNI/1Ksv6ShgbUQsKrkI1VtsnTjOi4jJETF55MiRJZs2M7MySj1kR9KbgONJh4LmAu+LiMWSdgVuB66pM9s7gPdLOgLYHthZ0qXAGkmjI2K1pNHA2ly/hbQn0mossKozH8rMzDqn7J7COcBiYN+IODkiFgNExCrS3sNmIuL0iBgbEeNJJ5B/FRHHAnOAabnaNOD6PDwHmCppkKQ9gAnAgk58JjMz66Syj+M8AngxIjYCSNoG2D4i/hIRl2zlMmcCsyWdAKwAPgQQEUskzQYeADYAJ7cuz8zMGqNsUrgFOAR4Po8PBm4G3l5m5oiYD8zPw08CU9qpNwOYUTImMzPrZmUPH20fEa0JgTw8uJqQzMysp5RNCi9I2r91RNIBwIvVhGRmZj2l7OGjU4ErJbVeDTQa+EglEZmZWY8plRQi4veS3gjsRbqf4KGI+GulkZmZWcOV3VMAeDMwPs+znyQi4uJKojIzsx5R9ua1S4DXAXcDrZeJBuCkYGbWh5TdU5gMTIyIzbqdMDOzvqPs1Uf3A6+tMhAzM+t5ZfcURgAPSFoArG8tjIj3VxKVmZn1iLJJ4cwqgzAzs+ZQ9pLUWyXtDkyIiFskDQb8VDQzsz6m7OM4PwlcBfwwF40BrqsoJjMz6yFlTzSfTHo+wrNQPHBnly3OYWZmvU7ZpLA+Il5uHZE0kDpPRTMzs96t7InmWyWdAeyQn838aeBn1YVlZj1h/PQbuzT/8plHdlMk1lPK7ilMB9YB9wH/DNxEO09cMzOz3qvs1UevAD/KLzMz66PK9n20jDrnECJiz26PyMzMeszW9H3UanvSc5WHd384ZmbWk8oePnqyTdFZkn4LfK37QzLrPl09cWrW35Q9fLR/zeg2pD2HIZVEZGZmPabs4aPv1gxvAJYDH+72aMzMrEeVPXz0nqoDMTOznlf28NHntzQ9Ir5XZ57tgduAQXk5V0XE1yUNB64gPdpzOfDhiHg6z3M6cALp6W6fiYhflv4kZmbWZWVvXpsMfIrUEd4Y4CRgIum8QnvnFtYD742IfYFJwGGS3kq6EW5eREwA5uVxJE0EpgJ7A4cB50pyT6xmZg20NQ/Z2T8ingOQdCZwZUR8or0Z8qM7n8+j2+ZXAEcDB+fyWcB84LRcfnlErAeWSVoKHAjcXv7jmJlZV5TdU9gNeLlm/GXS4Z8tkjRA0t3AWmBuRNwJjIqI1QD5vbW31THAyprZW3JZ2zZPlLRQ0sJ169aVDN/MzMoou6dwCbBA0rWkrf0PABd3NFNEbAQmSRoKXCtpny1UV70m6rR5HnAewOTJk91Tq5lZNyp79dEMST8HDspFx0fEXWUXEhHPSJpPOlewRtLoiFgtaTRpLwLSnsG4mtnGAqvKLsPMzLqu7OEjgMHAsxFxNtAiaY8tVZY0Mu8hIGkH4BDgIWAOMC1XmwZcn4fnAFMlDcptTwAWbEV8ZmbWRWUvSf066QqkvYAfk04aX0p6Glt7RgOz8hVE2wCzI+IGSbcDsyWdAKwg9aNERCyRNBt4gHSD3Mn58JOZmTVI2XMKHwD2AxYDRMQqSVvs5iIi7s3ztC1/EpjSzjwzgBklYzIzs25W9vDRy/kS0wCQtGN1IZmZWU8pmxRmS/ohMFTSJ4Fb8AN3zMz6nA4PH0kSqVuKNwLPks4rfC0i5lYcm5mZNViHSSEiQtJ1EXEA4ERgZtaHlT18dIekN1caiZmZ9biyVx+9BzhJ0nLgBdLdxxERb6oqMDMza7wtJgVJu0XECuDwBsVjZmY9qKM9hetIvaM+JunqiPifDYjJzMx6SEfnFGo7qduzykDMzKzndZQUop1hMzPrgzo6fLSvpGdJeww75GF49UTzzpVGZ2ZmDbXFpBARfhymmVk/sjVdZ5uZWR/npGBmZgUnBTMzKzgpmJlZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWaGypCBpnKRfS3pQ0hJJn83lwyXNlfRIfh9WM8/pkpZKeljSoVXFZmZm9ZV9RnNnbAC+EBGLJQ0BFkmaCxwHzIuImZKmA9OB0yRNBKYCewO7ArdIekNEbKwwRjPrRuOn39jpeZfPPLIbI7HOqmxPISJWR8TiPPwc8CAwBjgamJWrzQKOycNHA5dHxPqIWAYsBQ6sKj4zM9tcQ84pSBoP7AfcCYyKiNWQEgewS642BlhZM1tLLmvb1omSFkpauG7dukrjNjPrbypPCpJ2Aq4GTo2IZ7dUtU7ZZo8AjYjzImJyREweOXJkd4VpZmZUnBQkbUtKCD+JiGty8RpJo/P00cDaXN4CjKuZfSywqsr4zMxsU1VefSTgAuDBiPhezaQ5wLQ8PA24vqZ8qqRBkvYAJgALqorPzMw2V+XVR+8APgbcJ+nuXHYGMBOYLekEYAXwIYCIWCJpNvAA6cqlk33lkZlZY1WWFCLit9Q/TwAwpZ15ZgAzqorJzMy2zHc0m5lZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFIwM7NClb2kmnWLrjz318y2jvcUzMys4KRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZWcFIwM7OCk4KZmRWcFMzMrOCkYGZmhcqSgqQLJa2VdH9N2XBJcyU9kt+H1Uw7XdJSSQ9LOrSquMzMrH1V7ilcBBzWpmw6MC8iJgDz8jiSJgJTgb3zPOdKGlBhbGZmVkdlHeJFxG2SxrcpPho4OA/PAuYDp+XyyyNiPbBM0lLgQOD2quIzs+bSlY4Pl888shsj6d8afU5hVESsBsjvu+TyMcDKmnotuWwzkk6UtFDSwnXr1lUarJlZf9MsJ5pVpyzqVYyI8yJickRMHjlyZMVhmZn1L41OCmskjQbI72tzeQswrqbeWGBVg2MzM+v3Gp0U5gDT8vA04Pqa8qmSBknaA5gALGhwbGZm/V5lJ5ol/ZR0UnmEpBbg68BMYLakE4AVwIcAImKJpNnAA8AG4OSI2FhVbGZmVl+VVx/9YzuTprRTfwYwo6p4zMysY81yotnMzJqAk4KZmRWcFMzMrOCkYGZmBScFMzMrOCmYmVnBScHMzAqV3adgVqsrPWCaWeN4T8HMzApOCmZmVnBSMDOzgpOCmZkVnBTMzKzgpGBmZgVfkmpmvV5XLnlePvPIboyk9/OegpmZFbynYKX5BjSzvs97CmZmVnBSMDOzgpOCmZkVfE6hH/E5ATPriJOCmfVrvpx1Uz58ZGZmBe8pmJl1UlcPyTbjnkbTJQVJhwFnAwOA8yNiZg+H1FR8XsDMqtRUSUHSAOD/A38HtAC/lzQnIh7o2ci6l3/YzaxZNVVSAA4ElkbEowCSLgeOBipJCv5xNrOe1IwnuZstKYwBVtaMtwBvqa0g6UTgxDz6vKSHO2hzBPBEt0XYvRxb5zRrbM0aFzi2zmra2PSdLsW2e3sTmi0pqE5ZbDIScR5wXukGpYURMbmrgVXBsXVOs8bWrHGBY+us/hhbs12S2gKMqxkfC6zqoVjMzPqdZksKvwcmSNpD0nbAVGBOD8dkZtZvNNXho4jYIOl/A78kXZJ6YUQs6WKzpQ819QDH1jnNGluzxgWOrbP6XWyKiI5rmZlZv9Bsh4/MzKwHOSmYmVmhzyUFScMlzZX0SH4f1k69z0laIul+ST+VtH0TxTZU0lWSHpL0oKS3NUtsue4ASXdJuqHquMrGJmmcpF/n9bVE0mcrjOcwSQ9LWippep3pkvT9PP1eSftXFUsnYvtojuleSb+TtG+zxFZT782SNkr6YDPFJulgSXfn79etzRKbpNdI+pmke3Jsx3dpgRHRp17AvwHT8/B04Dt16owBlgE75PHZwHHNEFueNgv4RB7eDhjaLLHl6Z8HLgNuaKK/6Whg/zw8BPgDMLGCWAYAfwT2zH+be9ouBzgC+Dnpvpu3Anc2aD2Vie3twLA8fHgzxVZT71fATcAHmyU2YCipZ4Xd8vguTRTbGa3/E8BI4Clgu84us8/tKZC6xZiVh2cBx7RTbyCwg6SBwGAacz9Eh7FJ2hl4F3ABQES8HBHPNENsOb6xwJHA+Q2IqVWHsUXE6ohYnIefAx4kJf/uVnTFEhEvA61dsbSN9+JI7gCGShpdQSxbHVtE/C4ins6jd5DuBWqEMusN4BTgamBtg+IqG9v/Aq6JiBUAEdGo+MrEFsAQSQJ2IiWFDZ1dYF9MCqMiYjWkHwpgl7YVIuJPwH8AK4DVwJ8j4uZmiI20RbAO+HE+RHO+pB2bJDaAs4AvAa80IKZWZWMDQNJ4YD/gzgpiqdcVS9vkU6ZOFbZ2uSeQ9mgaocPYJI0BPgD8oEExtSqz3t4ADJM0X9IiSR9votjOAf6WtGF7H/DZiOj0/2dT3adQlqRbgNfWmfTlkvMPI2XbPYBngCslHRsRl/Z0bKS/yf7AKRFxp6SzSYdMvtrTsUk6ClgbEYskHdzVeNq03dX11trOTqQtzVMj4tnuiK3tIuqUtb2uu0ydKpRerqT3kJLCOyuNqGaRdcraxnYWcFpEbEwbvQ1TJraBwAHAFGAH4HZJd0TEH5ogtkOBu4H3Aq8D5kr6TWe//70yKUTEIe1Nk7RG0uiIWJ132evt5h0CLIuIdXmea0jHWrucFLohthagJSJat3KvIiWFLuuG2N4BvF/SEcD2wM6SLo2IY5sgNiRtS0oIP4mIa7oaUzvKdMXSU921lFqupDeRDv8dHhFPNiCusrFNBi7PCWEEcISkDRFxXRPE1gI8EREvAC9Iug3Yl3TuqqdjOx6YGemkwlJJy4A3Ags6s8C+ePhoDjAtD08Drq9TZwXwVkmD83G4KaRj0D0eW0Q8DqyUtFcumkJFXYd3IrbTI2JsRIwndUHyq+5ICN0RW/47XgA8GBHfqzCWMl2xzAE+nq9Ceivp8OTqCmMqHZuk3YBrgI81YCt3q2KLiD0iYnz+fl0FfLoBCaFUbKTv3EGSBkoaTOq9uRG/GWViW0H6nUDSKGAv4NFOL7ERZ9Ab+QL+BpgHPJLfh+fyXYGbaup9A3gIuB+4BBjURLFNAhYC9wLXka8WaYbYauofTOOuPuowNtJhkMjr7O78OqKieI4gbSH+EfhyLjsJOCkPi/SwqD+SjvFObsR6Khnb+cDTNetoYbPE1qbuRTTo6qOysQH/QtpAu590eLIpYsv/Bzfn79r9wLFdWZ67uTAzs0JfPHxkZmad5KRgZmYFJwUzMys4KZiZWcFJwczMCk4K1mtJ+nLuFfLe3HvlWzrZzqR8Q17r+Pu31Itnd8g9br69nWmjJN2Qe718QNJNVcZiVqtX3tFsptSd+FGknlHXSxpB6kWyMyaR7qa9CSAi5lD9s8EPBp4Hfldn2jeBuRFxNhR3IHeJpIER0elO0qz/8J6C9VajSd0OrAeIiCciYhWApAMk3Zo7Lvtlaw+luTOz70haIOkPkg7Kd4l+E/hI3tv4iKTjJJ2T57lI0n8qPavhUUnvlnSh0nMbLmoNRtLfS7pd0mJJV+Y+mJC0XNI3cvl9kt6YO+w7CfhcXuZBdT5bS+tIRNxbs5wv5XbukTQzl02SdEfeY7pW+XkT+fP+q1Lf/59tb72YbaJRd+X55Vd3vkhdBN9NutPzXODduXxb0tb3yDz+EeDCPDwf+G4ePgK4JQ8fB5xT03YxTrqz9nLSXcpHA88C/4O0QbWItJcxArgN2DHPcxrwtTy8nNS5IcCngfPz8JnAF9v5bIeSOmr8NalDwF1z+eH5sw3O4613dt9b8/m/CZxV83nP7Wi9+OVX7cuHj6xXiojnJR0AHAS8B7ginwdYCOxD6ikS0kNKavsdau0obxEwvuTifhYRIek+YE1E3AcgaUluYywwEfivvMztgNvbWeY/lPhsv5S0J3AYKRHcJWkfUkeOP46Iv+R6T0l6DekhTK1PApsFXFnT3BX5fS+2vF7MAJ9TsF4sIjaStobn5x/saaQf3iUR0d4jTNfn942U//63zvNKzXDr+MDc1tyI+MfuWmZEPEV6ut1lSo89fRdpb2Vr+6V5Ib+LLa8XM8DnFKyXkrSXpAk1RZOAx4CHgZH5RDSStpW0dwfNPUd6hGdn3QG8Q9Lr8zIHS3pDZ5cp6b25J04kDSH1kb+C1OnZP9VMGx4Rfwaerjkv8TGg3vODO7NerB9yUrDeaidgVr5k817S4ZszIz2y8IPAdyTdQzrvUPfSzxq/Bia2nmje2kAiPZfjOOCnOZY7SP3Zb8nPgA+0c6L5AGBhbut20nmI30fEL0hXRS2UdDfwxVx/GvDvuf4k0nmFtjF2Zr1YP+ReUs3MrOA9BTMzKzgpmJlZwUnBzMwKTgpmZlZwUjAzs4KTgpmZFZwUzMys8N+ya/JtHVsgwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a histogram of sentiment scores\n",
    "plt.hist(df['sentiment_score'], bins=20)\n",
    "plt.title('Distribution of Sentiment Scores')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57066/244784354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/corpora/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# bring corpus classes directly into package namespace, to save some typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mindexedcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIndexedCorpus\u001b[0m  \u001b[0;31m# noqa:F401 must appear before the other classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmmcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMmCorpus\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/corpora/indexedcorpus.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/interfaces.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;31m# try to load fast, cythonized code if possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_difference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/_matutils.pyx\u001b[0m in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "\n",
    "# Prepare data for topic modeling\n",
    "reviews_tokens = [simple_preprocess(review) for review in clean_reviews]\n",
    "\n",
    "# Remove stop words\n",
    "reviews_tokens_no_stop = [[word for word in doc if word not in STOPWORDS] for doc in reviews_tokens]\n",
    "\n",
    "# Create dictionary and corpus\n",
    "dictionary = corpora.Dictionary(reviews_tokens_no_stop)\n",
    "corpus = [dictionary.doc2bow(review) for review in reviews_tokens_no_stop]\n",
    "\n",
    "# Train LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10)\n",
    "\n",
    "# Print topics and their top 10 keywords\n",
    "for i, topic in lda_model.show_topics(num_topics=5, num_words=10, formatted=False):\n",
    "    print(f\"Topic {i+1}: {' '.join([word[0] for word in topic])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.5\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
